[INFO ] [2018-05-13 14:47:04] [Logging$class:logInfo:54] Running Spark version 2.2.1
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] Submitted application: anda_etl_pos_history_job
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] Changing view acls to: SAM
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] Changing modify acls to: SAM
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] Changing view acls groups to: 
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] Changing modify acls groups to: 
[INFO ] [2018-05-13 14:47:05] [Logging$class:logInfo:54] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(SAM); groups with view permissions: Set(); users  with modify permissions: Set(SAM); groups with modify permissions: Set()
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Successfully started service 'sparkDriver' on port 57321.
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registering MapOutputTracker
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registering BlockManagerMaster
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] BlockManagerMasterEndpoint up
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Created local directory at C:\Users\SAM\AppData\Local\Temp\blockmgr-111b2f8b-a467-418a-ae42-7d473604a42f
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] MemoryStore started with capacity 1992.0 MB
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registering OutputCommitCoordinator
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Successfully started service 'SparkUI' on port 4040.
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Bound SparkUI to 0.0.0.0, and started at http://192.168.0.152:4040
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Starting executor ID driver on host localhost
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57330.
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Server created on 192.168.0.152:57330
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registering BlockManager BlockManagerId(driver, 192.168.0.152, 57330, None)
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registering block manager 192.168.0.152:57330 with 1992.0 MB RAM, BlockManagerId(driver, 192.168.0.152, 57330, None)
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Registered BlockManager BlockManagerId(driver, 192.168.0.152, 57330, None)
[INFO ] [2018-05-13 14:47:06] [Logging$class:logInfo:54] Initialized BlockManager: BlockManagerId(driver, 192.168.0.152, 57330, None)
[ERROR] [2018-05-13 14:47:16] [LoadDataUtil$:loadFileToRdd:32] 数据文件路径不存在！
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] Invoking stop() from shutdown hook
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] Stopped Spark web UI at http://192.168.0.152:4040
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] MapOutputTrackerMasterEndpoint stopped!
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] MemoryStore cleared
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] BlockManager stopped
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] BlockManagerMaster stopped
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] OutputCommitCoordinator stopped!
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] Successfully stopped SparkContext
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] Shutdown hook called
[INFO ] [2018-05-13 14:47:17] [Logging$class:logInfo:54] Deleting directory C:\Users\SAM\AppData\Local\Temp\spark-cdd78162-a8d8-48e1-a014-3cff86c8bfac
